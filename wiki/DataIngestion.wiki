#summary Scripts that create and import the data into the Xenia database.

= Introduction =

These are the scripts currently running that retrieve the data from various sources and import that data into the Xenia database.



*Machine*: neptune.baruch.sc.edu <br/>
*Category*: Data Ingestion Scripts <br/>
*Process*: NetCDF Scout <br/>
*Script*: GetLatestData.pl <br/>
*Command line parameters*: <br/>
{{{
--URLControlFile is the XML file with the URL list the script will download the files from.
--FileFilter is the filter to apply to the file listings to allow the script to download the files we really want. Optional.
--DirForObsKml provides the path to the store the ObsKML files created. This is an optional argument, if not provided no ObsKML files are written.             
--Delete specifies we delete the netcdf files after we write the ObsKML files. This is an optional argument.
--NetCDFDir is the directory to store the downloaded files. Optional, default is ./latest_netcdf_files.
--FetchLogDir is the directory were the file time stamps are stored. The script uses these files to determine which files are really the latest. Optional, default is ./fetch_logs.             
 --UseLastNTimeStamps Integer representing the last N time entries to use when converting the data to obsKML. Optional.
--UseLastNTimeStampsForOrg Optional. List specifing orginization and the last N time entries to use for them. Whereas the UseLastNTimeStamps is applied to every organization, this can tailor to the specific. If not provided and UseLastNTimeStamps is provided, it is used. 
}}}
<br/>
*Directory*: /home/xeniaprod/scripts/scout/trunk<br/>
*Description*: Process netCDF files converting them into obsKML which are then processed by obskml_to_xenia_postgresql.pl to store the data into the database. This is scheduled to run in the crontab. NetCDF files for Carolinas RCOOS, NDBC, USF, NWS, NOS, and NCCOOS are processed. The obsKML files are then pulled into the database using the following scripts:<br/>



*Process*: populate_xenia_nws <br/>
*Script*: populate_xenia_nws <br/>
*Command line parameters*: <br/>
	Argument 1: Provider name – nos, nws, etc <br/>
	Argument 2: Not used <br/>
	Argument 3: Fully qualified path to SQL output file <br/>
*Directory*: /home/xeniaprod/scripts/postgresql/feeds/federal/nws <br/>
*Description*: Pulls in NWS data directly from the NWS site. This is used in tandem with the NetCDF scout. Currently this is scheduled to run in crontab. <br/>
*Shell Script Makeup* <br/>
	_Script_: mk_sql_for_xenia.pl <br/>
	_Command line parameters_: <br/>
		Argument 1: Provider name – nos, nws, etc <br/>
		Argument 2: Not used <br/>
		Argument 3: Fully qualified path to SQL output file <br/>
	_Description_: Connects to the NWS webservice, pulls the data down into a SQL file for importation into the database. Next psql is executed to import the SQL 	file.<br/>
	
*Process*: populate_xenia_nos <br/>
*Script*: populate_xenia_nos <br/>
*Directory*: /home/xeniaprod/scripts/postgresql/feeds/federal/nos <br/>
*Description*: Pulls in NOS data directly from the NOS site. This is used in tandem with the NetCDF scout. Currently this is scheduled to run in crontab. <br/>
*Shell Script Makeup* <br/>
	_Script_: mk_sql_for_xenia.pl <br/>
	_Command line parameters_: <br/>
		Argument 1: Provider name – nos, nws, etc <br/>
		Argument 2: Not used <br/>
		Argument 3: Fully qualified path to SQL output file	<br/>
	_Description_: Connects to the NOS webservice, pulls the data down into a SQL 	file for importation into the database. Next psql is executed to import the SQL 	file. <br/>

*Process*: feed_fit <br/>
*Script*: feed_fit.sh <br/>
*Directory*: /home/xeniaprod/cron <br/>
*Description*: Shell script that pulls in data from the Sebastion Inlet station in Florida. <br/>
*Shell Script Makeup* <br/>
	_Script_: fit_to_obskml.pl <br/>
	_Directory_: /home/xeniaprod/scripts/postgresql/feeds/fit <br/>
	_Description_: Process the Fit data. <br/>
	_Script_: obskml_to_xenia_postgresql.pl <br/>
	_Directory_: /home/xeniaprod/scripts/postgresql/import_export <br/>
	_Description_: Takes the obsKML and writes it into the database. <br/>


*Process*: getYSIData <br/>
*Script*: getYSIData.py <br/>
*Command line parameters*: <br/>
	Argument 1: /home/xeniaprod/config/ysiParseConfig.xml <br/>
*Directory*: /home/xeniaprod/ /scripts/postgresql/feeds/ysi <br/>
*Description*: Pulls in the data for the YSI site which is described in the configuration file 
provided  on the command line. This script pulls in the data for the Apache Pier. <br/>

*Process*: getYSIData <br/>
*Script*: getYSIData.py <br/>
*Command line parameters*: <br/>
	Argument 1: /home/xeniaprod/config/nerrsYSIConfigLinux.xml <br/>
*Directory*: /home/xeniaprod/ /scripts/postgresql/feeds/ysi <br/>
*Description*: Pulls in the data for the YSI site which is described in the configuration file 
provided  on the command line. This script pulls in the data for the some NERRS water quality sites. <br/>